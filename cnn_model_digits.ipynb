{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"cnn_model_digits","provenance":[{"file_id":"1OhcUKu09G8T6BU4iAYc7gCKxx1lUuMjH","timestamp":1630996198191},{"file_id":"/v2/external/notebooks/intro.ipynb","timestamp":1630996086371}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"rdApeGM4_144"},"source":["#Training script for Character Recognition Model\n","\n","### the train and test data is stored in gooogle drive\n","### we use image generators to load data and train model for character recognition\n"]},{"cell_type":"code","metadata":{"id":"TUSVFxezJmST","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630995121534,"user_tz":-330,"elapsed":31322,"user":{"displayName":"","photoUrl":"","userId":""}},"outputId":"962f4bef-fbf6-4ad3-a333-937ad24bd37c"},"source":["import math\n","from PIL import Image, ImageDraw\n","from PIL import ImagePath\n","import pandas as pd\n","import os\n","from os import path\n","from tqdm import tqdm\n","import json\n","import cv2\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import urllib\n","\n","from google.colab import drive\n","drive.mount('/content/drive',force_remount=True)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"bSB3mOYdKECS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630995135824,"user_tz":-330,"elapsed":395,"user":{"displayName":"","photoUrl":"","userId":""}},"outputId":"5f44ab34-0c6f-4632-ed00-e1581719a7d0"},"source":["%cd '/content/drive/MyDrive/mask_rcnn/'\n","!ls"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/mask_rcnn\n","character_recognition.h5\t\t  Mask_RCNN\t     p4.jpg\n","data\t\t\t\t\t  mask_rcnn_coco.h5  p5.jpg\n","download-accessory-list.jpeg\t\t  mask_rcnn_data     p6.png\n","img_20.jpg\t\t\t\t  no_plate.jpeg      p7.jpg\n","m1_epoch_9_loss1.6_1630737493.3999991.h5  p3.jpg\t     v1.h5\n"]}]},{"cell_type":"markdown","metadata":{"id":"NYNpgYIXbtNe"},"source":["# Loading the digits data saved in gdrive, with every class value stored in seperate directory."]},{"cell_type":"code","metadata":{"id":"F-7nKKkFKEJz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630995151172,"user_tz":-330,"elapsed":7901,"user":{"displayName":"","photoUrl":"","userId":""}},"outputId":"10689ae6-50b6-44e5-ceb8-08987e57de45"},"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","train_datagen = ImageDataGenerator(rescale=1./255, width_shift_range=0.1, height_shift_range=0.1)\n","\n","train_generator = train_datagen.flow_from_directory(\n","        'data/train',  # this is the target directory\n","        target_size=(28,28),  # all images will be resized to 28x28\n","        batch_size=1,\n","        class_mode='categorical')\n","\n","validation_generator = train_datagen.flow_from_directory(\n","        'data/val',  # this is the target directory\n","        target_size=(28,28),  # all images will be resized to 28x28        batch_size=1,\n","        class_mode='categorical')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 864 images belonging to 36 classes.\n","Found 216 images belonging to 36 classes.\n"]}]},{"cell_type":"code","metadata":{"id":"4x377bWaKVq9"},"source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Flatten, MaxPooling2D, Dropout, Conv2D\n","from tensorflow.keras import optimizers"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CMIoRAmWKc0o","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630995185159,"user_tz":-330,"elapsed":5997,"user":{"displayName":"","photoUrl":"","userId":""}},"outputId":"5dc7b5a8-1f99-4da7-8a24-c53c7c354652"},"source":["model = Sequential()\n","model.add(Conv2D(32, (24,24), input_shape=(28, 28, 3), activation='relu', padding='same'))\n","# model.add(Conv2D(32, (20,20), input_shape=(28, 28, 3), activation='relu', padding='same'))\n","# model.add(Conv2D(32, (20,20), input_shape=(28, 28, 3), activation='relu', padding='same'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.4))\n","model.add(Flatten())\n","model.add(Dense(128, activation='relu'))\n","model.add(Dense(36, activation='softmax'))\n","\n","model.compile(loss='categorical_crossentropy', optimizer=optimizers.Adam(lr=0.00001), metrics=['accuracy'])\n","model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d (Conv2D)              (None, 28, 28, 32)        55328     \n","_________________________________________________________________\n","max_pooling2d (MaxPooling2D) (None, 14, 14, 32)        0         \n","_________________________________________________________________\n","dropout (Dropout)            (None, 14, 14, 32)        0         \n","_________________________________________________________________\n","flatten (Flatten)            (None, 6272)              0         \n","_________________________________________________________________\n","dense (Dense)                (None, 128)               802944    \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 36)                4644      \n","=================================================================\n","Total params: 862,916\n","Trainable params: 862,916\n","Non-trainable params: 0\n","_________________________________________________________________\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"]}]},{"cell_type":"code","metadata":{"id":"epdDm0niKs1r"},"source":["import tensorflow as tf\n","class stop_training_callback(tf.keras.callbacks.Callback):\n","  def on_epoch_end(self, epoch, logs={}):\n","    print(\"keys : \",logs.items())\n","    if(logs.get('val_accuracy') !=-1):\n","      if (logs.get('val_accuracy')>= 0.992):\n","        self.model.stop_training = True "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NWa4re2nSzYj"},"source":["DESIRED_ACCURACY = 0.991\n","\n","class myCallback(tf.keras.callbacks.Callback):\n","    def on_epoch_end(self, epochs, logs={}) :\n","        if(logs.get('acc') is not None and logs.get('acc') >= DESIRED_ACCURACY) :\n","            print('\\nReached 99.9% accuracy so cancelling training!')\n","            self.model.stop_training = True\n","\n","callbacks = myCallback()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Dc-V-EUuTW6n","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630968582693,"user_tz":-330,"elapsed":8,"user":{"displayName":"","photoUrl":"","userId":""}},"outputId":"d70bf11e-aecd-4113-802d-208e8a7f3e4e"},"source":["history.history.keys()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["dict_keys(['loss', 'accuracy'])"]},"metadata":{},"execution_count":21}]},{"cell_type":"code","metadata":{"id":"ZTjHcXwSLCfu"},"source":["filepath=\"/path-model-{epoch:04d}.ckpt\"\n","model_checkpoint_callback= tf.keras.callbacks.ModelCheckpoint(filepath=filepath,\n","                                                              monitor='val_accuracy', verbose=1,\n","                                                              save_best_only=True,save_weights_only=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-Rh3-Vt9Nev9"},"source":["## More Resources\n","\n","### Working with Notebooks in Colab\n","- [Overview of Colaboratory](/notebooks/basic_features_overview.ipynb)\n","- [Guide to Markdown](/notebooks/markdown_guide.ipynb)\n","- [Importing libraries and installing dependencies](/notebooks/snippets/importing_libraries.ipynb)\n","- [Saving and loading notebooks in GitHub](https://colab.research.google.com/github/googlecolab/colabtools/blob/master/notebooks/colab-github-demo.ipynb)\n","- [Interactive forms](/notebooks/forms.ipynb)\n","- [Interactive widgets](/notebooks/widgets.ipynb)\n","- <img src=\"/img/new.png\" height=\"20px\" align=\"left\" hspace=\"4px\" alt=\"New\"></img>\n"," [TensorFlow 2 in Colab](/notebooks/tensorflow_version.ipynb)\n","\n","<a name=\"working-with-data\"></a>\n","### Working with Data\n","- [Loading data: Drive, Sheets, and Google Cloud Storage](/notebooks/io.ipynb) \n","- [Charts: visualizing data](/notebooks/charts.ipynb)\n","- [Getting started with BigQuery](/notebooks/bigquery.ipynb)\n","\n","### Machine Learning Crash Course\n","These are a few of the notebooks from Google's online Machine Learning course. See the [full course website](https://developers.google.com/machine-learning/crash-course/) for more.\n","- [Intro to Pandas](/notebooks/mlcc/intro_to_pandas.ipynb)\n","- [Tensorflow concepts](/notebooks/mlcc/tensorflow_programming_concepts.ipynb)\n","\n","<a name=\"using-accelerated-hardware\"></a>\n","### Using Accelerated Hardware\n","- [TensorFlow with GPUs](/notebooks/gpu.ipynb)\n","- [TensorFlow with TPUs](/notebooks/tpu.ipynb)"]},{"cell_type":"markdown","metadata":{"id":"P-H6Lw1vyNNd"},"source":["<a name=\"machine-learning-examples\"></a>\n","\n","## Machine Learning Examples\n","\n","To see end-to-end examples of the interactive machine learning analyses that Colaboratory makes possible, check out these  tutorials using models from [TensorFlow Hub](https://tfhub.dev).\n","\n","A few featured examples:\n","\n","- [Retraining an Image Classifier](https://tensorflow.org/hub/tutorials/tf2_image_retraining): Build a Keras model on top of a pre-trained image classifier to distinguish flowers.\n","- [Text Classification](https://tensorflow.org/hub/tutorials/tf2_text_classification): Classify IMDB movie reviews as either *positive* or *negative*.\n","- [Style Transfer](https://tensorflow.org/hub/tutorials/tf2_arbitrary_image_stylization): Use deep learning to transfer style between images.\n","- [Multilingual Universal Sentence Encoder Q&A](https://tensorflow.org/hub/tutorials/retrieval_with_tf_hub_universal_encoder_qa): Use a machine learning model to answer questions from the SQuAD dataset.\n","- [Video Interpolation](https://tensorflow.org/hub/tutorials/tweening_conv3d): Predict what happened in a video between the first and the last frame.\n"]}]}